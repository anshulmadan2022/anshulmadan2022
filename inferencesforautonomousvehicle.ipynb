{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGCWC8kHcnpQwpdULDC/mJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshulmadan2022/anshulmadan2022/blob/main/inferencesforautonomousvehicle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tIOshgY_4S42",
        "outputId": "e7ad3d94-42b1-4f68-a2ac-fbd2f91e028e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 1090.7498 - mae: 17.4025 - val_loss: 1056.4811 - val_mae: 17.0244\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1047.1364 - mae: 16.9215 - val_loss: 1011.8158 - val_mae: 16.4538\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 992.6952 - mae: 16.1556 - val_loss: 942.0109 - val_mae: 15.7094\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 946.5698 - mae: 15.7346 - val_loss: 843.8932 - val_mae: 14.8818\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 828.4421 - mae: 14.4682 - val_loss: 717.0230 - val_mae: 13.6781\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 731.7687 - mae: 13.6648 - val_loss: 571.5245 - val_mae: 12.1422\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 563.7271 - mae: 11.8730 - val_loss: 435.0101 - val_mae: 10.5430\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 397.3512 - mae: 10.0064 - val_loss: 334.3115 - val_mae: 9.3528\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 353.4644 - mae: 9.7677 - val_loss: 279.9646 - val_mae: 8.7094\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 300.2957 - mae: 9.1162 - val_loss: 263.8965 - val_mae: 8.6021\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 281.5512 - mae: 8.8936 - val_loss: 263.2868 - val_mae: 8.6343\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 284.3331 - mae: 9.0076 - val_loss: 264.5664 - val_mae: 8.6696\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 281.5889 - mae: 8.8116 - val_loss: 265.9093 - val_mae: 8.7063\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 286.2917 - mae: 8.9497 - val_loss: 266.5169 - val_mae: 8.7110\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 288.1754 - mae: 9.0430 - val_loss: 266.9813 - val_mae: 8.7088\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 278.3414 - mae: 8.8005 - val_loss: 267.7897 - val_mae: 8.7235\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 289.1548 - mae: 9.0434 - val_loss: 267.9748 - val_mae: 8.7388\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 281.4930 - mae: 8.9456 - val_loss: 267.7969 - val_mae: 8.7228\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 280.6781 - mae: 8.9754 - val_loss: 267.8533 - val_mae: 8.7212\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 275.4278 - mae: 8.8310 - val_loss: 268.3897 - val_mae: 8.7248\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 281.7186 - mae: 8.8679 - val_loss: 268.3741 - val_mae: 8.7270\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 271.8269 - mae: 8.6510 - val_loss: 268.1725 - val_mae: 8.7172\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 297.4666 - mae: 9.1525 - val_loss: 268.5028 - val_mae: 8.7369\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 274.1672 - mae: 8.8141 - val_loss: 268.2038 - val_mae: 8.7075\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 284.5022 - mae: 8.9748 - val_loss: 267.4303 - val_mae: 8.6978\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 265.8372 - mae: 8.6495 - val_loss: 268.0964 - val_mae: 8.7107\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 284.4321 - mae: 8.9434 - val_loss: 267.6313 - val_mae: 8.6995\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 300.3953 - mae: 9.2355 - val_loss: 268.2391 - val_mae: 8.7137\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 284.8746 - mae: 9.0262 - val_loss: 268.0764 - val_mae: 8.7031\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 282.8840 - mae: 8.9674 - val_loss: 267.9457 - val_mae: 8.7053\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 281.5921 - mae: 8.8943 - val_loss: 268.0709 - val_mae: 8.7088\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 268.8275 - mae: 8.7762 - val_loss: 268.1548 - val_mae: 8.7048\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 292.3784 - mae: 9.0792 - val_loss: 267.9826 - val_mae: 8.7100\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 272.1048 - mae: 8.8047 - val_loss: 267.6308 - val_mae: 8.6947\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 297.0788 - mae: 9.1342 - val_loss: 267.6245 - val_mae: 8.7005\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 279.2924 - mae: 8.8471 - val_loss: 267.6767 - val_mae: 8.6938\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 273.6668 - mae: 8.7330 - val_loss: 267.3331 - val_mae: 8.6879\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 271.1218 - mae: 8.6897 - val_loss: 267.7477 - val_mae: 8.6944\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 292.0111 - mae: 9.1577 - val_loss: 267.3870 - val_mae: 8.7001\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 274.5230 - mae: 8.8160 - val_loss: 267.2887 - val_mae: 8.6946\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 270.0096 - mae: 8.7355 - val_loss: 267.8546 - val_mae: 8.6948\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 275.2586 - mae: 8.7216 - val_loss: 267.3965 - val_mae: 8.6823\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 277.0667 - mae: 8.8356 - val_loss: 266.7750 - val_mae: 8.6775\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 273.4684 - mae: 8.8691 - val_loss: 266.9313 - val_mae: 8.6754\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 285.6030 - mae: 8.9947 - val_loss: 267.5310 - val_mae: 8.6901\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 279.8144 - mae: 8.8936 - val_loss: 267.1712 - val_mae: 8.6824\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 262.9615 - mae: 8.6152 - val_loss: 266.9285 - val_mae: 8.6758\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 283.8605 - mae: 8.9383 - val_loss: 267.1700 - val_mae: 8.6848\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 284.4838 - mae: 9.0107 - val_loss: 267.4308 - val_mae: 8.6862\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 276.0552 - mae: 8.8544 - val_loss: 266.8709 - val_mae: 8.6708\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 330.3443 - mae: 9.7225  \n",
            "Test MAE: 9.626328468322754\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "Confusion Matrix:\n",
            "[[54 45]\n",
            " [61 40]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.47      0.55      0.50        99\n",
            "         1.0       0.47      0.40      0.43       101\n",
            "\n",
            "    accuracy                           0.47       200\n",
            "   macro avg       0.47      0.47      0.47       200\n",
            "weighted avg       0.47      0.47      0.47       200\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 1028.2125 - mae: 16.8184 - val_loss: 1060.9408 - val_mae: 17.1335\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1037.3361 - mae: 16.8544 - val_loss: 1023.3408 - val_mae: 16.6362\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 998.6677 - mae: 16.3145 - val_loss: 966.9567 - val_mae: 15.9323\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 961.8588 - mae: 15.9301 - val_loss: 887.8032 - val_mae: 15.1026\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 864.8495 - mae: 14.8377 - val_loss: 781.6325 - val_mae: 14.1196\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 757.3259 - mae: 13.6019 - val_loss: 650.7845 - val_mae: 12.8206\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 661.4282 - mae: 12.9080 - val_loss: 507.1627 - val_mae: 11.2813\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 486.6352 - mae: 10.8803 - val_loss: 389.2697 - val_mae: 9.9129\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 401.5348 - mae: 10.2037 - val_loss: 309.8048 - val_mae: 9.0497\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 316.7047 - mae: 9.4142 - val_loss: 278.4376 - val_mae: 8.7092\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 293.6930 - mae: 9.1281 - val_loss: 270.4102 - val_mae: 8.7045\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 289.3144 - mae: 9.0584 - val_loss: 270.4418 - val_mae: 8.7193\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 290.3576 - mae: 9.0184 - val_loss: 270.0622 - val_mae: 8.7067\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 303.6867 - mae: 9.2454 - val_loss: 270.1535 - val_mae: 8.7077\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 284.6675 - mae: 8.9386 - val_loss: 270.2703 - val_mae: 8.7072\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 290.5366 - mae: 9.0000 - val_loss: 270.1730 - val_mae: 8.7097\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 290.4814 - mae: 9.1068 - val_loss: 269.7722 - val_mae: 8.6995\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 296.4861 - mae: 9.2309 - val_loss: 269.7367 - val_mae: 8.6852\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 283.0074 - mae: 8.9754 - val_loss: 270.4549 - val_mae: 8.7044\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 287.9833 - mae: 8.9900 - val_loss: 271.0832 - val_mae: 8.7207\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 280.5534 - mae: 8.9053 - val_loss: 270.8386 - val_mae: 8.7105\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 284.1115 - mae: 8.9849 - val_loss: 270.8508 - val_mae: 8.7084\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 286.4364 - mae: 8.9595 - val_loss: 270.6716 - val_mae: 8.7059\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 262.4673 - mae: 8.6590 - val_loss: 270.3130 - val_mae: 8.7070\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 286.4234 - mae: 8.9888 - val_loss: 270.9627 - val_mae: 8.7140\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 291.6474 - mae: 9.1480 - val_loss: 271.4073 - val_mae: 8.7066\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 285.6306 - mae: 9.0189 - val_loss: 270.6766 - val_mae: 8.7108\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 300.6227 - mae: 9.3612 - val_loss: 271.2498 - val_mae: 8.7211\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 287.6549 - mae: 8.9724 - val_loss: 270.6826 - val_mae: 8.7025\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 283.2319 - mae: 9.0394 - val_loss: 270.3386 - val_mae: 8.6984\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 269.0250 - mae: 8.6970 - val_loss: 270.9596 - val_mae: 8.6965\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 286.7476 - mae: 8.9585 - val_loss: 270.5160 - val_mae: 8.7011\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 272.1007 - mae: 8.7779 - val_loss: 270.6099 - val_mae: 8.7019\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 283.4097 - mae: 9.0440 - val_loss: 270.7737 - val_mae: 8.7076\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 282.0385 - mae: 8.9263 - val_loss: 271.2459 - val_mae: 8.7168\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 278.0600 - mae: 8.8430 - val_loss: 271.0514 - val_mae: 8.7100\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 264.9117 - mae: 8.6960 - val_loss: 271.0786 - val_mae: 8.7095\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 278.6488 - mae: 8.9502 - val_loss: 270.5166 - val_mae: 8.6966\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 282.5105 - mae: 8.9166 - val_loss: 270.4011 - val_mae: 8.6953\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 282.3924 - mae: 8.9160 - val_loss: 270.4155 - val_mae: 8.6957\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 298.8452 - mae: 9.2117 - val_loss: 271.7019 - val_mae: 8.7105\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 264.0482 - mae: 8.7157 - val_loss: 270.2212 - val_mae: 8.7021\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 278.6138 - mae: 8.8686 - val_loss: 270.1225 - val_mae: 8.6877\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 277.6614 - mae: 8.9075 - val_loss: 270.7413 - val_mae: 8.7000\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 284.1221 - mae: 8.9895 - val_loss: 271.1696 - val_mae: 8.7001\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 284.0385 - mae: 9.0326 - val_loss: 270.5751 - val_mae: 8.7134\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 289.4365 - mae: 9.0952 - val_loss: 270.4652 - val_mae: 8.7034\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 267.4850 - mae: 8.7176 - val_loss: 270.0859 - val_mae: 8.6871\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 261.6167 - mae: 8.6619 - val_loss: 270.4921 - val_mae: 8.6970\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 270.4648 - mae: 8.7717 - val_loss: 270.9658 - val_mae: 8.6966\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 329.3148 - mae: 9.7155  \n",
            "Test MAE: 9.620450973510742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7eb748600820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Confusion Matrix:\n",
            "[[66 33]\n",
            " [73 28]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "data_size = 1000\n",
        "X = np.random.rand(data_size, 4) * 10\n",
        "y_collision = np.random.randint(0, 2, data_size)\n",
        "y_route_efficiency = np.random.rand(data_size) * 5\n",
        "y_comfort = np.random.rand(data_size) * 100\n",
        "\n",
        "y = np.column_stack((y_collision, y_route_efficiency, y_comfort))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(3)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
        "print(f'Test MAE: {test_mae}')\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_true_collision = y_test[:, 0]\n",
        "y_pred_collision = np.round(y_pred[:, 0]).astype(int)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true_collision, y_pred_collision)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true_collision, y_pred_collision))\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "data_size = 1000\n",
        "X = np.random.rand(data_size, 4) * 10\n",
        "y_collision = np.random.randint(0, 2, data_size)\n",
        "y_route_efficiency = np.random.rand(data_size) * 5\n",
        "y_comfort = np.random.rand(data_size) * 100\n",
        "\n",
        "y = np.column_stack((y_collision, y_route_efficiency, y_comfort))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(3)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
        "print(f'Test MAE: {test_mae}')\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_true_collision = y_test[:, 0]\n",
        "y_pred_collision = np.round(y_pred[:, 0]).astype(int)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true_collision, y_pred_collision)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix for Collision Avoidance Prediction\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()\n"
      ]
    }
  ]
}